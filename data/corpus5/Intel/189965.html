Apple Will Take A Long Time To Make A Full Switch To ARM... Or Intel - Apple Inc. (NASDAQ:AAPL) | Seeking Alpha A recent article on Seeking Alpha asserted that Apple is going to make a complete switch toward ARM architecture. There is this conviction because ARM CPUs get similar or better performance per watt against Intel CPUs in certain synthetic benchmarks. This approach is wrong because performance per watt is completely different with higher TDPs. Comparing different architectures on different OSs and platform through synthetic benchamrks is completely wrong. The only way is to make comparisons is by real use applications. ARM architecture will take a lot of time to be really competitive in the desktop-workstation-server segment. Intel will not remain lazy regarding this. Recently, I read an article about Apple Inc. (NASDAQ: AAPL ) and its road to substitute Intel (NASDAQ: INTC ) CPUs with the Apple - ARM (ARM Holdings, plc (NASDAQ: ARMH )) self-designed architecture. The entire thesis and plan would make sense because self designing both mobile and desktop CPUs would greatly reduce costs and certainly increase profits. However, there is a single big flaw in the entire reasoning, a flaw that brings down the entire piece. The Apple A9 SoC is put at the same level of Intel desktop CPUs. The author probably considers truthful what Apple declared at the last keynote: Apple A9 is a desktop class SoC. Apple is talking about CPUs and SoCs with similar computational capacities, a very aggressive advertisement. This is supported by the fact that Apple considers its new SoCs faster than 80% of existing laptops. This is incredible! And this is the main reason why people think Apple could decide to design its own desktop CPUs. However, how do they compare those SoCs and CPUs? Such a comparison is generally made with synthetic benchmarks, and the author does not disprove this since it recalls Geekbench too. Apple A9 scores 2522 in single-core and 4403 in multi-core while the Core m7 6y75 scores 2711 in single-core and 5706 in multi-core (pre-series model). If we consider that Core M has a TDP of 4.5W while Apple A9 must have a TDP around 3.0W (a TDP below 3W would not meet Anandtech power analysis on iPhone and Apple tablets), it looks like performance per watt is somewhat equal or in Apple's favor. So, why do I not agree? Geekbench is not reliable at all, like any other bunch of synthetic benchmarks, moreover if you compare different architectures under different systems and OSs. For those who have read PC reviews for years, it's clear that only real world benchmarks have some kind of reliable index. If you make tons of tests with tons of real use applications, then you will have a good evaluation of what that CPU is capable of. On the contrary, synthetic benchmarks like Geekbench are not reliable when used between different architectures and OSs. There are variables like compilers, instruction sets, specific optimizations, microcodes and specific operations that can completely change the final result. Take Apple A9 (2015 - 16/14nm) and Intel Core M 5Y70 (2014 - 14nm) in 3D Mark Unlimited as an example: Intel SoC is faster by +164% in physics and +23% in graphics. Therefore, the problem is that these results do not mean anything reliable since they are too dependent on the program itself. We would need some real world application tests (or several benchmarks) that replicate real world program computation at least. Saying that A9 is equal to Core M, it's simply a marketing move without a real basis, and Apple knows it. For example, consider the AMD Athlon X2 +4800 (84W) and the Intel Pentium XE 840 (130W). The Intel CPU was faster by 30-40% in Sisoft Sandra, a synthetic benchmark, but when tested in various real programs, the Intel CPU was generally quite behind. This comparison is made between different architectures (but still X86) and the same OS, nevertheless results from synthetic benchmarks and real use were completely different. So, if what I am saying is right, how can we better compare different architectures? The best way would be having the same OS and running the same applications after that we could evaluate the SoCs and CPUs by testing a lot. This way is not practicable until it will be possible to run some tests on Windows 10 with continuum (the new Lumia could give us some great insight). Nowadays, the only way is to use Linux based benchmarks like SPEC CPU2000, which replicates quite well the server and workstation load. For example, we could look at the comparison between 2014 Apple A8 (20nm) and 2006 Intel Xeon LV 1.66 (65nm) in the following table. Notice that we are talking about the SPECint_2000, which is practically a single thread and not a multi-core benchmark. This implies that there's no hint about the multi-thread capacity, and considering the TDP is quite difficult and misleading. As you can see the performances are quite similar. However Apple A8 is obviously more efficient since it has a TDP around 3W while the Xeon is at 31W (the Xeon effective TDP is practically lower since the 31W TDP was reached only by Xeon LV 2.16). But, if we get more insight, we must look at things from a different point of view: Comparing CPUs < 4W against CPUs >30W or more is simply wrong: the relation between power consumption and performances is roughly exponential due to leakage current problems. The lower is the requested speed, the lower will be the requested voltage and the generated power. But the lower is the generated power, the lower will be the leakage current and consequently lower voltage will be sufficient. In the above image, the matter is more clear: once you cut the frequency from 3.2 GHz to 1.6 GHz, the i7-3770K improves its performance per watt by 45%. In our case, the leap from 25W/30W to 5W of power consumption would imply a better performance per watt by 110%. This kind of comparison is specific to those CPUs but the reasoning can be applied to every kind of CPU from a qualitative point of view. This behavior is supported by the following image that shows how leakage current grows dramatically with the required performances. This specific behavior tells us that considering the SoC efficiency at 4W is totally different from doing it at 40W or 70W. A synthetic intensive benchmark immediately pushes a low power SoC to its TDP limits. It's different for desktop CPUs: CPUs reach their thermal limits after some time, which means that the initial required power is quite below the specific TDP. In addition, only the top CPU of each TDP series reached the declared TDP. The Apple A8 architecture was designed in 2013-2014, while the Xeon LV 1.66 was designed in 2004-2005. Such a difference is biblical in informatics terms. We find that Apple A8 has a 20nm node technology while the Xeon was made with 65nm node technology. The node technology reduction can be exploited better only at very low TDPs: when a CPU must work at tens of watts, the benefits from miniaturization get massively restrained due to leakage currents. If we consider a very low power consumption segment (below one watt), the leap from 65nm to 22/20nm would have brought a better performance per watt around +500%. Such behavior becomes more clear if we look at the following table: Notice that Haswell architecture was not heavily focused on working at such low TDPs. You can see that it's possible to achieve better efficiency at low TDPs. At the same time both architectural evolutions and technology node innovations give enormous results at low TDPs and they are constrained at higher TDPs. Just from here, it's very hard to compare such different architectures from different periods, technologies and so on. The comparison between different CPU targets is completely wrong, without any doubt. It also is completely wrong to think that a 3W TDP ARM SoC, which works well in Geekbench, could be the same at much higher TDP values in real usage. Now, I want to show you what Intel has managed to do with the server CPUs in the 40W TDP range, picking up similar CPUs from 2006 ( Intel Xeon 5148 LV - 65nm) and 2014 ( Intel Xeon E3-1275L v3 - 22nm): Notice that I had to use SPEC CPU2006 and not the 200 version. The 2000 version is not used in the desktop and server environment anymore. These tables simply support the previous part: the miniaturization and architectural evolutions are remarkable but still constrained by the high TDP. Well, till this point, I have explained why it's hard to compare different architectures and CPUs with different technology nodes. But mostly, I have explained why comparing different CPUs with different TDPs is completely wrong. Finally, I want to show you why ARM architecture has a long way to go before achieving similar performances to Intel CPUs. Anandtech has showed that the actual server ARM SoCs from Applied Micro are still quite bad . This is caused by the 40nm technology node that they used for the XGene-1, which is a customization of the ARM A57-A53 cores. The Intel offer instead was at 22nm. As you can see, the XGene-1 performs a very low performance per watt. The company declared that the XGene-2, which will have some architectural optimization, will come with +50% of efficiency thanks to the 28nm node. Moreover, if that architecture was made with a 22nm node, it would probably still achieve lower results compared to Intel, but it would not be so far from the Atom solution. The problem is that the Avaton Atom was derived from architectural improvements of the 2010-2011 development line, a quite old architecture compared to the ARM-v8a which has been designed in the years 2012-2013. Remember that Intel's focus on low consumption is a relatively fresh focus. It also is true that XGene-3 will be a 16nm FF+ SoC powered by customized A72 cores, but at the same time Intel is using Broadwell to substitute the server Atom offer. The pre-production Xeon D series will provide better performance per watt by +30-40% compared to Avaton Atom. In addition, Intel is going to release the Skylake server offer in 4Q 2015, which will bring additional efficiency. There also are other competitors like Cavium ThunderX. If we take a look at some pre-series internal tests , it looks like the 48 cores version (80W) obtains 350 point at SPECint_rate 2006, while the Intel Xeon E5-2650L v3 single CPU (65W) obtains 437 points. This implies roughly 76% of performance per watt in Intel's favor. In addition, the ThunderX is an updated architecture while the Intel one is an old project. As for the node technology, Cavium still uses a 28nm against Intel's 22nm, which historically brings 10% of additional efficiency at those TDPs. Various ARM producers are still behind in technology node, architecture performances and power consumption while others are quite closer to Intel (Cavium is an example). Clearly, we could see an ARM CPU close the gap in coming years if Intel does not accelerate on development. In the meantime, Intel is increasing its server velocity upgrade since it's going to show two new server architectures in 2015 (1Q Broadwell - 4Q Skylake). Just from this, I would say that ARM will still take a lot of time to close the gap before it begins to be really compelling (the development for server and workstation programs takes time). And it's not granted that ARM will manage to always improve like it's doing nowadays. At the same time it would be strange seeing Intel not accelerating on development given its declared laziness in the last few years. You also must consider what Intel has managed to do when it released the Haswell v3 series (like E5-2650L v3): compared to the desktop counterpart (4 cores) it managed to improve performance per watt by 100% exploiting lower frequencies and a higher core number. This kind of approach is similar to what ARM producers are doing: If Intel decides to heavily exploit this way, expect great results. But despite this, I think this is not enough to really believe that the ARM switch is long to happen. In fact, there are other considerations to be done. First of all, Apple has higher sales thanks to full Windows compatibility. In fact, once Apple announced the switch over from Power PC, Mac sales increased a lot in comparison to Windows PC sales. A total switch to ARM would cut-off a substantial part of those who need Windows, since the Microsoft (Microsoft Corporation (NASDAQ: MSFT )) OS is still extremely important in the IT environment. Secondly, Apple switched from the PowerPC architecture when Intel got higher performances around +50/+60%, an enormous gap. In addition, the Intel inability to provide a sufficient and good mobile offer is not equal to the PowerPC inability of those years, moreover when workstations, PCs and professional laptops serve customers with completely different needs. From this point of view, it may also be possible that Apple is waiting for Intel's next mobile offer in the coming two to three years, given that Intel is increasing a lot the mobile development and is already testing Core M on big smartphones. At the same time, Intel is accelerating on all-in-one SoC series to be released in 2016-2017 . An Apple-like behavior would be waiting and studying any possible future innovation from its partners, Intel included, when things are not clear. And things are not clear now. Third, Apple makes deep considerations before doing ecosystem transitions. A complete switch is problematic in terms of convenience, timing and capability. It would have to spend a lot in research and building to assure the right support for multi-core, drivers, APIs, PCI-e, I/O and a lot of other features in order to scale them from iPhone to Mac Pro. Furthermore, Apple waited for Intel to have the upper-hand in the PC field to make the switch, so it's likely to wait and see what ARM producers are able to do at desktop-server TDP segments. Designing ARM SoCs for the mobile segment is a completely different matter than designing ARM SoCs for the desktop segment: Apple has no real experience in that field and ARM producers are starting to show something interesting only in the server field. To conclude, Tim Cook has just declared that Apple has no intention to merge iOS and OSx . He wants them to be two separated and distinct operative systems. He also said that having different operating systems provide the best experience for those different needs. This kind of declaration sounds like a stop to ARM switch-over, because it would cut off the compatibility and interoperability that characterizes the Mac offer. It does not mean that a full architectural switch is completely impossible in their plans, but it means that it's more difficult to happen any time soon. In this scenario, Apple will have to wait a lot of time before it will be possible to raise profits by self-designing desktop CPUs. Surely, such a plan would crush costs and theoretically massively raise profits from Mac sales, but given Apple's behavior in such policies and given the Windows compatibility influence, Apple will wait a long time before making a total switch. In addition, Mac sales are around 20 million units per year, therefore the self designing would bring cost reduction for no more than $2 billion, less than 5% of profit growth (not accounting for lower sales due to the compatibility absence for X86 applications/OSs). Moreover, Apple will likely look at what Intel will be able to offer in the next few years: we know that ARM architecture is going very well, but Intel is becoming more and more interesting in the mobile sector. Intel is planning to release all-in-one SoCs in the coming two years while it's going to close the gap in the Atom development line: remember that the latest Atom architecture comes from Broadwell and not Skylake, therefore expect consistent better performance next year thanks to Kaby Lake derived architecture. In addition, Intel still has the chance to raise the core number and to lower frequencies to obtain great performance per watt, and it's already looking at that. I would not be surprised to see Apple considering Intel instead for a total switch, someday in the future. Nowadays, do not expect any deep change for Apple. Its revenues and profits will remain highly dependent on the iPhone business for some time. Keep an eye on Intel instead, because it may start to be compelling in the mobile business in the next coming years. We only use your contact details to reply to your request for more information. We do not sell the personal contact data you submit to anyone else. Thank you for your interest in Seeking Alpha PRO We look forward to contacting you shortly for a conversation. Thank you for your interest in Seeking Alpha PRO Our PRO subscription service was created for fund managers, and the cost of the product is prohibitive for most individual investors.  If you are an investment professional with over $1M AUM and received this message in error, click here and you will be contacted shortly. Thank you for your interest in Seeking Alpha PRO We look forward to contacting you when we have an individual investor product ready! 