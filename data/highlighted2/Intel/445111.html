<html><style> .textDiv { width: 900px; border: 25px solid #58D3F7; padding: 25px; margin: 25px; font-family: 'Arial', Times, serif; font-size: 16px; text-align: justify;} .title { margin: 50px 50px 50px 25px; font-family: 'Arial', Times, serif; font-size: 40px; font-weight: bold; color:  #58D3F7; text-align: left;} </style><head></head><body><div class='title'>Intel</div><div class='textDiv'><span style='background-color: #A9E2F3'>Intel </span>Destroying Nvidias Artificial Intelligence Lead <span style='background-color: #A9E2F3'>Intel </span>Corporation NASDAQINTC Seeking Alpha <span style='background-color: #A9E2F3'>Intel </span>has made its second generation Xeon Phi a perfect fit for artificial intelligence Nvidia on the other hand has made its new Tesla P GPU accelerators to offer huge computing horsepower Diane Bryant head of Intels NASDAQ INTC datacenter group said at Computex in Taipei that the companys Knights Landing KNL processors could be the perfect fit for AI artificial intelligence in terms of running ML machine learning or DL deep learning workloads KNL represents Intels second generation x Xeon Phi family According to Bryant since the latest Xeon Phi coprocessors feature up to cores and each core has <span style='background-color: #A9E2F3'>Intel </span>AVX SIMD processing units for delivering improved percore floatingpoint performance these processors are ideal for running MLDL workloads However it remains to be seen if these processors can surpass Nvidias NASDAQ NVDA new Tesla P GPU accelerators which are currently considered the best fit for MLDL Nvidia Needs To Retain Its Competitive Edge Nvidia jumped on the MLDL bandwagon with its powerful GPUs coupled with better algorithms Although its not clear yet if <span style='background-color: #A9E2F3'>Intel </span>can displace Nvidias Tesla P GPU accelerators which are based on the latters new Pascalbased GP GPU <span style='background-color: #A9E2F3'>Intel </span>is certainly wellpositioned than before Pascal is Nvidias th generation CUDA architecture The company took three years and spent billion to build Tesla P which is currently in volume production Players like IBM NYSE IBM Cray NASDAQ CRAY HewlettPackard Enterprise NYSE HPE and privatelyheld Dell are already using P for their upcoming HPC high performance computing serves and supercomputers Delivering the required computing horsepower for HPC and supercomputers via accelerated computing is nothing new Regarding the performance of its earlier version of Tesla K GPU accelerators compared to Xeon Phi Nvidia said that simply recompiling and running applications on Intels Xeon Phi without changing CPU code usually resulted in deceleration instead of acceleration Further programming a GPU and Xeon Phi used to need similar effort but the GPU delivered meaningfully better performance According to Nvidia Once you see the facts a better understanding of accelerated computing emerges Today a GPU provides double the performance for essentially the same developer effort GPUs are the logical choice for accelerating parallel code In part this could be why scientific researchers have published with GPUs more than over <span style='background-color: #A9E2F3'>Intel </span>Xeon Phi this year And why NVIDIA GPU is favored more than over Xeon Phi in HPC systems today However these facts were presented three years ago and todays scenario could be entirely different with <span style='background-color: #A9E2F3'>Intel </span>significantly improving its latest Xeon Phi and supporting tools In the following section I will try to assess if <span style='background-color: #A9E2F3'>Intel </span>can displace Nvidias GPUs this time around for running MLDL workloads <span style='background-color: #A9E2F3'>Intel </span>Better Prepared This Time Around Intels KNL x Xeon Phi is capable of delivering teraflops of FP compute horsepower ie bit double precision arithmetic Although consumer grade GPUs dont support double precision arithmetic Nvidia has made Tesla P to deliver teraflops of FP compute power for beating the KNL Xeon Phi However despite Nvidias Tesla P offers higher standalone FP performance in terms of performance per dollar this is insignificant at the system level Beating <span style='background-color: #A9E2F3'>Intel </span>in running MLDL workloads could be difficult for Nvidia due to three reasons which are given below Intels AVX advanced vector extensions SIMD processing units will support MLDL algorithms like floatingpoint multiply and fused multiplyadd <span style='background-color: #A9E2F3'>Intel </span>has empowered the latest Xeon Phi so that the OS can boot itself via a selfboot socket Finally with Intels unique omnipath architecture OPA fabric technology supporting the Xeon Phi the processor will be a supercomputing beast For programming the second generation Xeon Phi similar effort by developers as for Tesla P might not result in significantly better performance for the latter which was the case three years ago In fact <span style='background-color: #A9E2F3'>Intel </span>has made it a lot easier than before to parallelize MLDL code with <span style='background-color: #A9E2F3'>Intel </span>MKL math kernel library The latest version of <span style='background-color: #A9E2F3'>Intel </span>MKL ie the <span style='background-color: #A9E2F3'>Intel </span>MKL beta includes new tools for optimizing MLDL neural networks For raw computing horsepower Tesla P should be the obvious choice But for running MLDL workloads raw computing horsepower isnt always the priority With cloud computing increasingly impacting MLDL research a comprehensive HPC platform with massive storage capacity is what researchers need In addition better optimization tools are also required I strongly believe that Intels scalable system framework SSF HPC platform based on its omnipath architecture will make all the difference in favor of <span style='background-color: #A9E2F3'>Intel </span>I shared my view regarding Intels SSF approach in a previous article When the latest Xeon Phi coprocessors will be used alongside Intels new highestend Xeon processors and D XPoint memorybased Optane SSDs MLDL workloads will certainly get a performance boost In addition <span style='background-color: #A9E2F3'>Intel </span>is providing more tools in the hands of developers via software libraries It is optimizing its core architecture also for opensource ML frameworks like Caffe and Theano If raw computing horsepower isnt the priority latest Xeon Phi should be the best choice AI will go mainstream very slowly with the advent of autonomous cars smart homes and the like Nvidia has developed sophisticated AIbased autonomous vehicle technology which could take a decade before going mainstream due to lack of adequate infrastructure Oftentimes building a technology takes lesser time than building adequate infrastructure for its proper utilization Nvidia will continue to generate most of its revenues from its graphics business despite developing advanced technology for autonomous vehicles <span style='background-color: #A9E2F3'>Intel </span>on the other hand is continuously creating new revenue streams for the future Thats why I am more bullish on <span style='background-color: #A9E2F3'>Intel </span>Disclosure I amwe are long INTC IBM I wrote this article myself and it expresses my own opinions I am not receiving compensation for it other than from Seeking Alpha I have no business relationship with any company whose stock is mentioned in this article Tagged Investing Ideas Long Ideas Technology </div></body></html>